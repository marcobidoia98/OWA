{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Yym5nvt_D9ZK"
   },
   "outputs": [],
   "source": [
    "#Required libraries and functions\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.stats import rankdata\n",
    "from scipy.interpolate import interp1d\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "JiRBAyYoDvJa"
   },
   "outputs": [],
   "source": [
    "#Measure of similarity to OR operator\n",
    "\n",
    "def orness(w_ord):\n",
    "\n",
    "    '''\n",
    "    Function to measure orness according to original Yager,1988 formula\n",
    "    ORDER WEIGHTS SHOULD BE IMPUTED IN DESCENDING ORDER\n",
    "    such that w_ord[0] is the weight associate with the MAX\n",
    "    and w_ord[n] is the weight associated with the MIN\n",
    "    '''\n",
    "\n",
    "    w_ord = np.array(w_ord)\n",
    "    n = len(w_ord)\n",
    "\n",
    "    coef = np.arange(n-1,-1,-1)\n",
    "    value = w_ord.dot(coef)/(n-1)\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "p0wiehq0JQOe"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#OWA: naive version - Yager, 1988\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mowa\u001b[39m(data:[\u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mSeries, pd\u001b[38;5;241m.\u001b[39mDataFrame, np\u001b[38;5;241m.\u001b[39marray], w_imp, w_ord) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m np\u001b[38;5;241m.\u001b[39marray:    \u001b[38;5;66;03m#as data, only pd.Series, pd.DataFrames and np.arrays are accepted; w_int, w_fin: any mono-dimensional iterable.\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;03m    Function to compute ordered weighted average of a dataset \u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;03m    composed of n. observation*n. criteria,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;124;03m    if no importance weights,it is sufficient to set w_imp = 1\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     w_ord \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mflip(w_ord) \u001b[38;5;66;03m#This is required to be aligned with next OWA computations since numpy sorts only in ascending order\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#OWA: naive version - Yager, 1988\n",
    "\n",
    "def owa(data:[pd.Series, pd.DataFrame, np.array], w_imp, w_ord) -> np.array:    #as data, only pd.Series, pd.DataFrames and np.arrays are accepted; w_int, w_fin: any mono-dimensional iterable.\n",
    "\n",
    "    '''\n",
    "    Function to compute ordered weighted average of a dataset \n",
    "    composed of n. observation*n. criteria,\n",
    "    data = pd.Series/pd.DataFrame\n",
    "    w_int = importance weights\n",
    "    w_ord = order weights\n",
    "    ORDER WEIGHTS SHOULD BE IMPUTED IN DESCENDING ORDER\n",
    "    such that w_ord[0] is the weight associate with the MAX\n",
    "    and w_ord[n] is the weight associated with the MIN,\n",
    "    if no importance weights,it is sufficient to set w_imp = 1\n",
    "    '''\n",
    "\n",
    "    w_ord = np.flip(w_ord) #This is required to be aligned with next OWA computations since numpy sorts only in ascending order\n",
    "\n",
    "\n",
    "    w_imp = np.array(w_imp)\n",
    "    w_ord = np.array(w_ord)\n",
    "\n",
    "    if type(data).__module__ != np.__name__:\n",
    "       data = data.to_numpy()\n",
    "\n",
    "    int_res = data * w_imp # intermediate results = importance weights x raw values\n",
    "    int_res = np.sort(int_res, axis = 1) # sort intermediate results in ascending order\n",
    "    values = int_res.dot(w_ord) # final product with order weights and sum\n",
    "\n",
    "    return int_res\n",
    "\n",
    "owa(test_dta, test_w_imp, test_w_ord.loc[att,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EEyslOcS5fWc",
    "outputId": "2000bc30-d02d-4ceb-da23-41f323a5748d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.166, 0.35 , 0.18 , 0.09 ])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WOWA - Torra, 1998\n",
    "\n",
    "def  wowa(data:[pd.Series, pd.DataFrame, np.array], w_imp, w_ord) -> np.array:    #as data, only pd.Series, pd.DataFrames and np.arrays are accepted; w_imp, w_ord: any mono-dimensional iterable\n",
    "\n",
    "    '''\n",
    "    Function to compute WOWA of a dataset \n",
    "    composed of n. observation*n. criteria,\n",
    "    the interpolation function chosen is linear interpolation,\n",
    "    data = pd.Series/pd.DataFrame\n",
    "    w_int = importance weights\n",
    "    w_fin = order weights\n",
    "    ORDER WEIGHTS SHOULD BE IMPUTED IN DESCENDING ORDER, \n",
    "    such that w_ord[0] is the weight associate with the MAX\n",
    "    and w_ord[n] is the weight associated with the MIN\n",
    "    '''\n",
    "\n",
    "    w_imp = np.array(w_imp)\n",
    "    w_ord = np.array(w_ord)\n",
    "\n",
    "    if type(data).__module__ != np.__name__:\n",
    "        data = data.to_numpy()\n",
    "\n",
    "    w_ord_cum = np.cumsum(np.insert(w_ord,0,0))\n",
    "    points = np.arange(0,w_ord.shape[0]+1)/w_ord.shape[0]\n",
    "    \n",
    "    #To ensure that the function is robust to numerical errors (i.e. rounding)\n",
    "    w_ord_cum = np.insert(w_ord_cum, len(w_ord_cum), 1)\n",
    "    points = np.insert(points, len(points), 1.1)\n",
    "        \n",
    "    #Compute the interpolation function needed to determine the final weights, note that w_ord is in still in \"descending order\" here\n",
    "    int_fun = interp1d(points, w_ord_cum)\n",
    "    int_fun_vect = np.vectorize(int_fun) #vectorize function, to enable its application to np.arrays\n",
    "\n",
    "    #sort the importance weights array according to the order of the values (\"observation specific\")\n",
    "    w_imp_long = np.full((data.shape[0],data.shape[1]),w_imp)\n",
    "    sorted_ind = np.argsort(data, axis = 1) #Automatically sorts in ascending order\n",
    "    w_imp_long = np.take_along_axis(w_imp_long,sorted_ind,axis=1) \n",
    "\n",
    "    #Compute the final weights applying linear interpolation\n",
    "    quant_fun = int_fun_vect(np.cumsum(np.flip(w_imp_long,1), axis = 1))  #This operations should be done with importance weights sorted according to observation values, but in descending order (np.flip())\n",
    "    w_fin = np.diff(quant_fun, axis = 1, prepend = 0)\n",
    "\n",
    "    #multiply the final weights (different for every observation) for the values, and compute the final sum\n",
    "    values = (np.take_along_axis(data,sorted_ind,axis=1)*np.flip(w_fin,1)).sum(axis=1)  #np.take_along_axis(data.to_numpy(),sorted_ind,axis=1) is the same as np.sort(data.to_numpy())\n",
    "    \n",
    "    return values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEhm6f2H1eYf",
    "outputId": "cd869a9a-6cbc-49e6-edf8-0d3363cdd306"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.166, 0.35 , 0.18 , 0.09 ])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#WOWA - Torra, 1998 (optimized version, if n. unique(weights) << n. of dataset rows)\n",
    "\n",
    "\n",
    "def  wowa(data:[pd.Series, pd.DataFrame, np.array], w_imp, w_ord) -> np.array:    #as data, only pd.Series, pd.DataFrames and np.arrays are accepted; w_imp, w_ord: any mono-dimensional iterable\n",
    "\n",
    "    '''\n",
    "    Function to compute WOWA of a dataset \n",
    "    composed of n. observation*n. criteria,\n",
    "    the interpolation function chosen is linear interpolation,\n",
    "    data = pd.Series/pd.DataFrame\n",
    "    w_int = importance weights\n",
    "    w_fin = order weights\n",
    "    ORDER WEIGHTS SHOULD BE IMPUTED IN DESCENDING ORDER, \n",
    "    such that w_ord[0] is the weight associate with the MAX\n",
    "    and w_ord[n] is the weight associated with the MIN\n",
    "    '''\n",
    "\n",
    "    w_imp = np.array(w_imp)\n",
    "    w_ord = np.array(w_ord) \n",
    "\n",
    "    if type(data).__module__ != np.__name__:\n",
    "        data = data.to_numpy()\n",
    "\n",
    "    w_ord_cum = np.cumsum(np.insert(w_ord,0,0))\n",
    "    points = np.arange(0,w_ord.shape[0]+1)/w_ord.shape[0]\n",
    "    \n",
    "    #To ensure that the function is robust to numerical errors (i.e. rounding)\n",
    "    w_ord_cum = np.insert(w_ord_cum, len(w_ord_cum), 1)\n",
    "    points = np.insert(points, len(points), 1.1)\n",
    "        \n",
    "    #Compute the interpolation function needed to determine the final weights, note that w_ord is in still in \"descending order\" here\n",
    "    int_fun = interp1d(points, w_ord_cum)\n",
    "    int_fun_vect = np.vectorize(int_fun) #vectorize function, to enable its application to np.arrays\n",
    "\n",
    "    #sort the importance weights array according to the order of the values (\"observation specific\")\n",
    "    w_imp_long = np.full((data.shape[0],data.shape[1]),w_imp)\n",
    "    sorted_ind = np.argsort(data, axis = 1) #Automatically sorts in ascending order\n",
    "    w_imp_long = np.take_along_axis(w_imp_long,sorted_ind,axis=1) \n",
    "\n",
    "    #Compute the final weights applying linear interpolation (to all the combinations of cumulative sum of weights in the dataset)\n",
    "    unique_comb, indices = np.unique(np.cumsum(np.flip(w_imp_long,1),axis = 1),axis=0, return_inverse = True) # computes the interpolation function for all the possible combinations of cumulative sums of weights in the dataset\n",
    "    quant_fun = int_fun_vect(unique_comb)                                                                     #This operations should be done with importance weights sorted according to observation values, but in descending order (np.flip())\n",
    "    w_fin = np.diff(quant_fun, axis = 1, prepend = 0)\n",
    "    w_fin = w_fin[indices] #attributes the right final weights to the whole dataset, reconstructing the array \n",
    "\n",
    "    #multiply the final weights (different for every observation) for the values, and compute the final sum\n",
    "    values = (np.take_along_axis(data,sorted_ind,axis=1)*np.flip(w_fin,1)).sum(axis=1)  #np.take_along_axis(data.to_numpy(),sorted_ind,axis=1) is the same as np.sort(data.to_numpy())\n",
    "    \n",
    "    return values\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
